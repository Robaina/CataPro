{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6bc28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Starting model download process...\n",
      "Preparing to download 'Rostlab/prot_t5_xl_uniref50' into 'models/prot_t5_xl_uniref50'...\n",
      "/home/ubuntu/miniconda/envs/proteus/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "spiece.model: 100%|███████████████████████████| 238k/238k [00:00<00:00, 162MB/s]\n",
      "special_tokens_map.json: 1.79kB [00:00, 12.2MB/s]\n",
      "tokenizer_config.json: 100%|██████████████████| 24.0/24.0 [00:00<00:00, 237kB/s]\n",
      "config.json: 100%|█████████████████████████████| 546/546 [00:00<00:00, 5.77MB/s]\n",
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "pytorch_model.bin: 100%|████████████████████| 11.3G/11.3G [00:43<00:00, 258MB/s]\n",
      "Successfully downloaded and saved 'Rostlab/prot_t5_xl_uniref50'.\n",
      "------------------------------\n",
      "Preparing to download 'laituan245/molt5-base-smiles2caption' into 'models/molt5-base-smiles2caption'...\n",
      "spiece.model: 100%|███████████████████████████| 792k/792k [00:00<00:00, 130MB/s]\n",
      "special_tokens_map.json: 1.79kB [00:00, 10.9MB/s]\n",
      "tokenizer_config.json: 2.13kB [00:00, 12.7MB/s]\n",
      "config.json: 100%|█████████████████████████████| 699/699 [00:00<00:00, 6.72MB/s]\n",
      "pytorch_model.bin: 100%|█████████████████████| 990M/990M [00:09<00:00, 99.1MB/s]\n",
      "Successfully downloaded and saved 'laituan245/molt5-base-smiles2caption'.\n",
      "------------------------------\n",
      "\n",
      "Model download complete!\n",
      "Your models are now available in the 'models' directory.\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!python download_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37ebc9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "For sequence  1\n",
      "For sequence  2\n",
      "For sequence  3\n",
      "For sequence  4\n",
      "For sequence  5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "docker run --rm --gpus all \\\n",
    "  -v /home/ubuntu/lab4/CataPro/samples:/app/samples \\\n",
    "  -v /home/ubuntu/lab4/CataPro/models:/app/models \\\n",
    "  protscout-tools-catapro \\\n",
    "  -inp_fpath /app/samples/sample_inp.csv \\\n",
    "  -model_dpath /app/models \\\n",
    "  -batch_size 64 \\\n",
    "  -device cuda:0 \\\n",
    "  -out_fpath /app/samples/catapro_prediction.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
